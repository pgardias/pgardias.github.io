---
layout: page
title: Link Aggregator
---

Useful references from around the web, annotated for search brevity.

<a name="dl"></a>
### Deep Learning  

[Deep Learning](http://www.deeplearningbook.org/) by Goodfellow, Bengio and Courville is a free online textbook  

[Efficient Backprop](http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf) by Yann LeCun covers tips tuning neural networks through backpropagation  

[The Lottery Ticket Hypothesis](https://arxiv.org/abs/1803.03635) by Frankle and Carbin explores the concept of winning ticket random weight initializations that allow subnetworks within feed-forward neural networks to train comparably to those created using standard pruning techniques 

[Why Deep Learning Works Even Though It Shouldn't](https://moultano.wordpress.com/2020/10/18/why-deep-learning-works-even-though-it-shouldnt/) by Ryan Moulton discusses ideas for optimizing deep network weights given the nature of high-dimensional spaces 

A number of helpful sources for approaching linear algebra:
<div style="margin-left: 25px;" markdown=1>
- [Matrix Cookbook](https://www.math.uwaterloo.ca/~hwolkowi/matrixcookbook.pdf) by Petersen and Pedersen is a collection of identities, approximations, inequalities, etc. about matrices
- [Essense of Linear Algebra](https://www.3blue1brown.com/essence-of-linear-algebra-page/) by Grant Sanderson (3Blue1Brown) is a video series that provides fantastic visual comprehension of linear algebra concepts
- [Viewing Matrices & Probability as Graphs](https://www.math3ma.com/blog/matrices-probability-graphs) interprets matrices as relations
- [A Programmer's Intuition for Matrix Multiplication](https://betterexplained.com/articles/matrix-multiplication/) describes matrices as collections of data and functions
</div>  
 
[The Sorcerer’s Apprentice Guide to Training LSTMs](https://www.niklasschmidinger.com/posts/2020-09-09-lstm-tricks/) describes tips for fitting timeseries data and references:
<div style="margin-left: 25px;" markdown=1>
- [A Recipe for Training Neural Networks](http://karpathy.github.io/2019/04/25/recipe/) by Andrej Karpathy
- [Tips for Training Recurrent Neural Networks](https://danijar.com/tips-for-training-recurrent-neural-networks/) by Danijar Hafner
- [LSTM: A Search Space Odyssey](https://ieeexplore.ieee.org/document/7508408/) by Greff et al.
</div> 

[Graph Neural Network resources](https://twitter.com/PetarV_93/status/1306689702020382720), a Twitter thread by Petar Veličković, contains great resources covering the state of graph neural networks  

<a href="https://arogozhnikov.github.io/einops/pytorch-examples.html" style="font-weight: 500;" markdown=1><span style="color: DarkSlateBlue;" markdown=1>ein</span>ops</a> is a PyTorch tensor modification library which easily abstracts complex transformations and has a handy [intro](https://github.com/arogozhnikov/einops/tree/master/docs)  

[Weight-Agnostic Neural Networks](https://weightagnostic.github.io/) demonstrates the success of neural networks without training, focusing on optimal weight initialization for reinforcement learning and classical supervised learning tasks  

[OpenAI Microscope](https://microscope.openai.com/models) visualizes features of a collection of convolutional neural networks using [lucid](https://github.com/tensorflow/lucid)

[VGG Image Annotator (VIA)](http://www.robots.ox.ac.uk/~vgg/software/via/) is a simple, self-contained image, audio, and video annotation tool


<a name="essays"></a>
### Essays  

[The Bitter Lesson](http://incompleteideas.net/IncIdeas/BitterLesson.html) by Rich Sutton reminds of the reality of working with persistent computational power growth  

[You and Your Research](http://www.cs.virginia.edu/~robins/YouAndYourResearch.pdf) by Richard Hamming reflects on his years at Bell Labs and research success  

[You Cannot Serve Two Masters](http://www.argmin.net/2018/08/09/co-employment/) by Ben Recht discusses industry misdirection of academic work away from "curiosity driven research"  

[Programming essays list](https://www.benkuhn.net/progessays/) by Ben Kuhn is a collection of essays citeable in technical conversation  

[Your Life is Driven by Network Effects](https://www.nfx.com/post/your-life-network-effects/) describes levels of networking over the course of your life  


<a name="util"></a>
### Utilities  

[Detexify](https://detexify.kirelabs.org/classify.html) converts character sketches to LaTeX  

[Vimium](https://vimium.github.io/) lets you quickly browse the web using your keyboard Vim-style with alternatives available for most modern browesers [\[1\]](https://apps.apple.com/us/app/vimari/id1480933944?mt=12) [\[2\]](https://addons.mozilla.org/en-US/firefox/addon/vimium-ff/) [\[3\]](https://microsoftedge.microsoft.com/addons/detail/vimium-c-all-by-keyboar/aibcglbfblnogfjhbcmmpobjhnomhcdo)  

<a href="https://www.libreoffice.org/" style="font-weight: 500;"><span style="color: green;">Libre</span>Office</a> is a free office software suite including a word processor, spreadsheet editor, etc.

[LyX](https://www.lyx.org/) is a word processor built on top of LaTeX made for great writing right out of the box


<a name="other"></a>
### Other  
[Artvee](https://artvee.com) is a source of high resolution, public domain art  

[The Eye](https://the-eye.eu/public/) is a digital library that includes [datasets](https://the-eye.eu/public/AI/pile_preliminary_components/) and National Gallery [paintings](https://the-eye.eu/public/Images/National%20Gallery%20Paintings/)  

[strml.net](https://strml.net) by Samuel Reed is an interactive website inspired by the work of [Jake Albaugh](https://codepen.io/jakealbaugh/)  

[aem1k.com](https://aem1k.com/) by Martin Kleppe hosts an assortment of unique, simple JavaScript projects  
